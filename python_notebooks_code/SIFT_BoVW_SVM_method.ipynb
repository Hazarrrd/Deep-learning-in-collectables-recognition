{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SIFT_SVN_OLD.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOVClGDmzo6iPIbaVOEanJG"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EFpoefh1ieiP"},"source":["!pip install opencv-python==3.4.2.17\n","!pip install opencv-contrib-python==3.4.2.17"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TB9qxI3wefe5"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import random\n","import os\n","from torch import optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms\n","import torch.nn as nn\n","from torchvision.utils import make_grid\n","from torchvision.utils import save_image\n","from IPython.display import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import shutil,os,os.path\n","from os import listdir\n","from os.path import isfile, join\n","from PIL import Image, ImageEnhance\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os, subprocess, zipfile\n","from collections import defaultdict\n","from scipy import ndimage\n","from scipy.spatial import distance\n","from sklearn.cluster import KMeans\n","import random\n","from sklearn import svm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_V83UL3lzPf"},"source":["# Connet to Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# GPU/CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jd0d74dhnZM2"},"source":["SEED = 1000\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cH9pn7ghnguA"},"source":["def load_dataset_helper(download_dir, working_dir, datafile):\n","  if not os.path.exists(working_dir):\n","        base_dir = '/content/work/'\n","\n","        if os.path.isfile(os.path.join(base_dir,datafile)) == False: \n","          !rsync -ah --progress '$download_dir'$datafile '$base_dir'\n","        else:\n","          print('already exists!')\n","\n","        try:\n","          os.mkdir(working_dir)\n","        except OSError:\n","          print (\"Creation of the directory %s failed\" % working_dir)\n","        else:\n","          print (\"Successfully created the directory %s \" % working_dir)\n","\n","        path_to_zip = os.path.join(download_dir,datafile)\n","        print(path_to_zip)\n","        !unzip $path_to_zip -d $working_dir\n","\n","        print(\"Directory \" , working_dir ,  \" Created \")\n","  else:    \n","        print(\"Directory \" , working_dir ,  \" already exists\")\n","\n","\n","def load_dataset(first_datafile = 'coins_kings'):\n","    first_datafile += \".zip\"\n","    #YOU NEED TO CHANGE THIS DOWNLOAD_DIR PATH FOR YOUR VALID PATH!!!!!!!!!!!!!!!!!!!\n","    download_dir = '/content/gdrive/My\\ Drive/magisterka/'\n","    working_dir = '/content/work'\n","\n","    load_dataset_helper(download_dir, working_dir, first_datafile )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHSU5WbsUUm4"},"source":["!rm -R /content/work\n","file = 'coins_kings'\n","load_dataset(file)\n","\n","train_dir = '/content/work/'+file+'/train'\n","test_dir = '/content/work/'+file+'/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jx1shKT652_1"},"source":["def crop_mask(mask, masked_data):\n","  _,thresh = cv2.threshold(mask,1,255,cv2.THRESH_BINARY)\n","  contours = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n","  x,y,w,h = cv2.boundingRect(contours[0])\n","  crop = masked_data[y:y+h,x:x+w]\n","  return crop\n","\n","def circular_tiling(img):\n","  height,width = img.shape\n","  mask2 = np.zeros((height,width), np.uint8)\n","  mask3 = np.zeros((height,width), np.uint8)\n","  mask6 = np.zeros((height,width), np.uint8)\n","  circle_img6 = cv2.circle(mask6,(int(height/2),int(width/2)),int(width/6),(255,255,255),thickness=-1)\n","  circle_img3 = cv2.circle(mask3,(int(height/2),int(width/2)),int(width/3),(255,255,255),thickness=-1) - circle_img6\n","  circle_img2 = cv2.circle(mask2,(int(height/2),int(width/2)),int(width/2),(255,255,255),thickness=-1) - circle_img3 - circle_img6\n","\n","\n","  masked_data6 = cv2.bitwise_and(img, img, mask=circle_img6)\n","  masked_data3 = cv2.bitwise_and(img, img, mask=circle_img3)\n","  masked_data2 = cv2.bitwise_and(img, img, mask=circle_img2)\n","\n","  return [crop_mask(mask2,masked_data2), crop_mask(mask3,masked_data3), crop_mask(mask6,masked_data6)]\n","\n","def load_images_from_folder(folder):\n","    images = {}\n","    images_list =[]\n","    for filename in os.listdir(folder):\n","        category = []\n","        path = folder + \"/\" + filename\n","        for cat in os.listdir(path):\n","            #img = cv2.imread(path + \"/\" + cat,0)\n","            img = cv2.imread(path + \"/\" + cat)\n","            img = img[:,:int(img.shape[1])] ## img.shape[1]/2\n","            #img = cv2.resize(img, (330,330))\n","            img = cv2.resize(img, (520,260))\n","            if img is not None:\n","                category.append(img)\n","                images_list.append((len(img)))\n","        images[filename] = category\n","    return images, images_list\n","    \n","def sift_features(images):\n","    sift_vectors = {}\n","    descriptor_list = []\n","    sift = cv2.xfeatures2d.SIFT_create()\n","    for key,value in images.items():\n","        features = []\n","        for img in value:\n","            kp, des = sift.detectAndCompute(img,None)\n","           \n","            \n","            descriptor_list.extend(des)\n","            features.append(des)\n","        sift_vectors[key] = features\n","    return [descriptor_list, sift_vectors]\n","\n","def sift_features_with_circular_tiling(images):\n","    sift_vectors = {}\n","    descriptor_list = []\n","    sift = cv2.xfeatures2d.SIFT_create()\n","    for key,value in images.items():\n","        features = []\n","        for img in value:\n","            img_parts = circular_tiling(img)\n","            img_features = []\n","            for part in img_parts:\n","              kp, des = sift.detectAndCompute(part,None)\n","                  \n","              descriptor_list.extend(des)\n","              img_features.append(des)\n","            features.append(img_features)\n","        sift_vectors[key] = features\n","    return [descriptor_list, sift_vectors]\n","\n","def kmeans(k, descriptor_list):\n","    kmeans = KMeans(n_clusters = k, n_init=10)\n","    kmeans.fit(descriptor_list)\n","    visual_words = kmeans.cluster_centers_ \n","    return visual_words\n","\n","def image_class(all_bovw, centers):\n","    dict_feature = {}\n","    for key,value in all_bovw.items():\n","        category = []\n","        for img in value:\n","            histogram = np.zeros(len(centers))\n","            for each_feature in img:\n","                ind = find_index(each_feature, centers)\n","                histogram[ind] += 1\n","            category.append(histogram)\n","        dict_feature[key] = category\n","    return dict_feature\n","\n","def image_class_with_circular_tiling(all_bovw, centers):\n","    dict_feature = {}\n","    for key,value in all_bovw.items():\n","        category = []\n","        for img in value:\n","            img_histograms = []\n","            for part in img:\n","              part_histogram = np.zeros(len(centers))\n","              for each_feature in part:\n","                  ind = find_index(each_feature, centers)\n","                  part_histogram[ind] += 1\n","              img_histograms.extend(part_histogram)\n","            category.append(img_histograms)\n","        dict_feature[key] = category\n","    return dict_feature\n","    \n","# Find the index of the closest central point to the each sift descriptor. \n","# Takes 2 parameters the first one is a sift descriptor and the second one is the array of central points in k means\n","# Returns the index of the closest central point.  \n","def find_index(image, center):\n","    count = 0\n","    ind = 0\n","    for i in range(len(center)):\n","        if(i == 0):\n","           count = distance.euclidean(image, center[i]) \n","        else:\n","            dist = distance.euclidean(image, center[i]) \n","            if(dist < count):\n","                ind = i\n","                count = dist\n","    return ind"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vbf765-KbQQ5"},"source":["train_images, train_list = load_images_from_folder(train_dir)\n","test_images, test_list = load_images_from_folder(test_dir)\n","print(train_list[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VR6J4pBjVCM"},"source":["plt.hist(train_list+test_list, bins=10,edgecolor='black', linewidth=1.2)\n","#plt.hist(test_list, bins=10,edgecolor='black', linewidth=1.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ble2YvcIs4f2"},"source":["import random\n","img = train_images['Alexander III'][0]\n","rows = 10\n","cols = 6\n","fig = plt.figure(figsize = (4*cols, 4*rows))\n","idx = 0\n","choosen_imgs = []\n","for key in ['Elizabeth', 'Alexander III', 'Franz Joseph I', 'Leopold I', 'Friedrich Wilhelm I', 'Maximilian III Jose', 'Augustus III the Sas', 'John III Sobieski', 'Neron', 'Hadrian']:\n","  img_list = random.sample(train_images[key], cols)\n","  for img in img_list:\n","    choosen_imgs.append((img,key))\n","\n","for img, key in choosen_imgs:\n","  ax = fig.add_subplot(rows, cols, idx+1)\n","  ax.imshow(img[:,:260,::-1])\n","  ax.set_title(key)\n","  ax.axis('off')\n","  idx +=1\n","\n","fig.savefig('gdrive/MyDrive/magisterka/samples_obverses.png')\n","  \n","#images = images.permute(0,2,3,1)\n","       \n","#plt.imshow(img, cmap='gray')\n","#plt.imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zddt_WLbY255"},"source":["fig = plt.figure(figsize = (3*cols, 3*rows))\n","idx=0\n","for img,key in choosen_imgs:\n","  ax = fig.add_subplot(rows, cols, idx+1)\n","  ax.imshow(img[:,260:,::-1])\n","  ax.set_title(key)\n","  ax.axis('off')\n","  idx +=1\n","\n","fig.savefig('gdrive/MyDrive/magisterka/samples_reverses.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1VXj_ybQpnl"},"source":["img_circles = circular_tiling(img)\n","plt.imshow(img_circles[1], cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-3lzxA4gqkR"},"source":["img = train_images['Alexander III'][0]\n","img_circles = circular_tiling(img)\n","sift = cv2.xfeatures2d.SIFT_create()\n","kp, _ = sift.detectAndCompute(img_circles[2],None)\n","img=cv2.drawKeypoints(img_circles[2],kp,img_circles[2])\n","\n","plt.imshow(img, cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hb25dYxYcbyh"},"source":["def dic_of_features_to_X_Y(dict_feature):\n","  list_feature = []\n","  for label, label_imgs_list in dict_feature.items():\n","    for img_feature in label_imgs_list:\n","      list_feature.append((label,img_feature))\n","  random.shuffle(list_feature)\n","  Y, X = zip(*list_feature)\n","  return X, Y\n","\n","def save_checkpoint(save_path, dict_feature_train, dict_feature_test, words):\n","    if save_path==None:\n","        return\n","    save_path = save_path \n","    state_dict = {'dict_feature_train': dict_feature_train,\n","                  'dict_feature_test':dict_feature_test,\n","                  'words': words}\n","\n","    torch.save(state_dict, save_path)\n","\n","    print(f'Model saved to ==> {save_path}')\n","\n","def load_checkpoint(path):\n","    save_path = path\n","    state_dict = torch.load(save_path)\n","    dict_feature_train = (state_dict['dict_feature_train'])\n","    dict_feature_test = (state_dict['dict_feature_test'])\n","    words = state_dict['words']\n","    print(f'Model loaded from <== {save_path}')\n","    \n","    return dict_feature_train, dict_feature_test, words\n","\n","\n","save_path ='/content/gdrive/MyDrive/magisterka/' + 'SIFT_kings_one_side_50_circular_tiling.pt'\n","save_checkpoint(save_path,dict_feature_train,dict_feature_test,words)\n","#dict_feature_train, dict_feature_test, words =load_checkpoint(save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHuJ5zwAkeF7"},"source":["descrip_list_train, sift_vect_train = sift_features_with_circular_tiling(train_images)\n","#words = kmeans(50,descrip_list_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNK7CJHIsR2e"},"source":["#descrip_list_train, sift_vect_train = sift_features(train_images)\n","dict_feature_train = image_class_with_circular_tiling(sift_vect_train, words)\n","_, sift_vect_test = sift_features_with_circular_tiling(test_images)\n","dict_feature_test = image_class_with_circular_tiling(sift_vect_test, words) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_WDAiM-R61f"},"source":["X, y = dic_of_features_to_X_Y(dict_feature_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKrTePAqEFjV"},"source":["clf = svm.SVC(C = 1.0, probability=True)\n","clf.fit(X,y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6_d8vjn2gxb"},"source":["!pip install scikit-metrics \n","!pip install scikit-learn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0scUDP2BUNWV"},"source":["import sklearn.metrics as metrics\n","\n","\n","# evaluation metrics\n","def eval(model, X, Y):\n","  correct = 0\n","  # print('Starting Iteration')\n","  count = 0\n","\n","  preds = model.predict(X)\n","\n","  for i in range(len(Y)):\n","      if preds[i] == Y[i]:\n","        correct = correct+1      \n","      count = count +1\n","\n","  accuracy = (correct/count)*100\n","    \n","  y_test = Y\n","  y_pred = preds\n","  print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n","  print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='macro'))\n","  print(\"F1 score:\",metrics.f1_score(y_test, y_pred, average='macro'))\n","  print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='macro'))\n","  print(\"Confusion matrix:\",metrics.confusion_matrix(y_test, y_pred))\n","  return accuracy\n","\n","  \n","X_test, Y_test = dic_of_features_to_X_Y(dict_feature_test)\n","eval(clf,X_test, Y_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q50EFWMMcSF5"},"source":["def knn(images, tests):\n","    num_test = 0\n","    correct_predict = 0\n","    class_based = {}\n","    \n","    for test_key, test_val in tests.items():\n","        class_based[test_key] = [0, 0] \n","        for tst in test_val:\n","            predict_start = 0\n","            minimum = 0\n","            key = \"a\" \n","            for train_key, train_val in images.items():\n","                for train in train_val:\n","                    if(predict_start == 0):\n","                        minimum = distance.euclidean(tst, train)\n","                        key = train_key\n","                        predict_start += 1\n","                    else:\n","                        dist = distance.euclidean(tst, train)\n","                        if(dist < minimum):\n","                            minimum = dist\n","                            key = train_key\n","            \n","            if(test_key == key):\n","                correct_predict += 1\n","                class_based[test_key][0] += 1\n","            num_test += 1\n","            class_based[test_key][1] += 1\n","    return [num_test, correct_predict, class_based]\n","     \n","results_bowl = knn(dict_feature_train, dict_feature_test) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNyFnCPIcW6T"},"source":["print(\"Accuracy KNN: \" + str((100*results_bowl[1])/results_bowl[0]))"],"execution_count":null,"outputs":[]}]}