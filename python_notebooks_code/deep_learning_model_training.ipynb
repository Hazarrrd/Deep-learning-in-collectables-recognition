{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deeplearningmodel.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNYTk8xdAsSGr+bwJdti93H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TB9qxI3wefe5"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import random\n","import os\n","from torch import optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms\n","import torch.nn as nn\n","from torchvision.utils import make_grid\n","from torchvision.utils import save_image\n","from IPython.display import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import shutil,os,os.path\n","from os import listdir\n","from os.path import isfile, join\n","from PIL import Image, ImageEnhance\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os, subprocess, zipfile\n","from tqdm.autonotebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaO-_LWQnQr9"},"source":["!pip install tqdm lap\n","!pip install efficientnet_pytorch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_V83UL3lzPf"},"source":["# Connet to Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# GPU/CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jd0d74dhnZM2"},"source":["SEED = 1000\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cH9pn7ghnguA"},"source":["def load_dataset_helper(download_dir, working_dir, datafile):\n","  if not os.path.exists(os.path.join(working_dir,datafile)):\n","        base_dir = '/content/work/'\n","\n","        if os.path.isfile(os.path.join(base_dir,datafile)) == False: \n","          !rsync -ah --progress '$download_dir'$datafile '$base_dir'\n","        else:\n","          print('already exists!')\n","\n","        try:\n","          os.mkdir(working_dir)\n","        except OSError:\n","          print (\"Creation of the directory %s failed\" % working_dir)\n","        else:\n","          print (\"Successfully created the directory %s \" % working_dir)\n","\n","        #with zipfile.ZipFile(os.path.join(base_dir,datafile)) as zf:\n","        #  for member in tqdm(zf.infolist(), desc='Extracting '):\n","        #      try:\n","        #        zf.extract(member, working_dir)\n","        #      except zipfile.error as e:\n","        #          pass\n","        path_to_zip = os.path.join(download_dir,datafile)\n","        print(path_to_zip)\n","        !unzip $path_to_zip -d $working_dir\n","\n","        print(\"Directory \" , working_dir ,  \" Created \")\n","  else:    \n","        print(\"Directory \" , working_dir ,  \" already exists\")\n","\n","\n","def load_dataset(first_datafile = 'coins_kings'):\n","    first_datafile += \".zip\"\n","    #YOU NEED TO CHANGE THIS DOWNLOAD_DIR PATH FOR YOUR VALID PATH\n","    download_dir = '/content/gdrive/My\\ Drive/magisterka/'\n","    working_dir = '/content/work'\n","    #working_dir_task_2_3 = '/content/work/task_2_3'\n","\n","    load_dataset_helper(download_dir, working_dir, first_datafile )\n","    #load_dataset_helper(download_dir, working_dir_task_2_3, second_datafile )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj8c__ETFP4Y"},"source":["def give_mean_std(datasetloader):\n","  pop_mean = []\n","  pop_std0 = []\n","  pop_std1 = []\n","\n","  images, labels = iter(datasetloader).next()\n","\n","  numpy_image = images.numpy()\n","  \n","  batch_mean = np.mean(numpy_image, axis=(0,2,3))\n","  batch_std0 = np.std(numpy_image, axis=(0,2,3))\n","  batch_std1 = np.std(numpy_image, axis=(0,2,3), ddof=1)\n","  \n","  pop_mean.append(batch_mean)\n","  pop_std0.append(batch_std0)\n","  pop_std1.append(batch_std1)\n","\n","  pop_mean = np.array(pop_mean).mean(axis=0)\n","  pop_std0 = np.array(pop_std0).mean(axis=0)\n","  pop_std1 = np.array(pop_std1).mean(axis=0)\n","  print(str(pop_mean) + \" \" + str(pop_std0) + \" \" + str(pop_std1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHSU5WbsUUm4"},"source":["!rm -R /content/work\n","file_type = 'coins_kings'\n","for i in range(5):\n","  file = 'folds_data_packages/' + file_type +\"_fold\"+str(i+1)\n","  load_dataset(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHZg2D04JNvN"},"source":["class OneCoinSideDataset(torchvision.datasets.ImageFolder):\n","  def __init__(self, root, kings, transform):\n","    super(OneCoinSideDataset, self).__init__(root, transform)\n","    self.kings = kings\n","\n","  def __getitem__(self, index):\n","    \"\"\"\n","    Args:\n","      index (int): Index\n","    Returns:\n","      tuple: (sample, resnet, target) where target is class_index of the target class.\n","    \"\"\"\n","    path, target = self.samples[index]\n","    sample = self.loader(path)\n","    if self.kings:\n","      sample = sample.crop((0, 0, sample.width/2, sample.height))\n","    else:\n","      sample = sample.crop(((sample.width/2), 0, sample.width, sample.height))\n","    if self.transform is not None:\n","      sample = self.transform(sample)\n","    if self.target_transform is not None:\n","      target = self.target_transform(target)\n","    return sample, target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2fo_Zp8qdIt"},"source":["folds_paths=[]\n","for i in range(5):\n","  folds_paths.append('/content/work/'+file_type+\"_fold\"+str(i+1))\n","\n","dataset_size = 10000\n","TRAIN_PCT = 0.81\n","trainset_size = int(dataset_size * TRAIN_PCT)\n","valset_size = dataset_size - trainset_size\n","width = 260\n","height = 260\n","dimensions = (width, height)\n","\n","#400 x 500\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","#Applying Transformation\n","means,stds = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","train_transforms = transforms.Compose([\n","                                transforms.Resize(dimensions),\n","                                transforms.RandomRotation(5),\n","                                #transforms.RandomResizedCrop(224),\n","                                transforms.RandomHorizontalFlip(),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(means,stds),\n","                                ])\n","\n","means,stds = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","test_transforms = transforms.Compose([transforms.Resize(dimensions),\n","                                      #transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize(means,stds),\n","                                      ])\n","\n","batch_size=32\n","test_set_fold_indx = 4 #0-4\n","\n","#test_data = OneCoinSideDataset(folds_paths[test_set_fold_indx],False, transform=test_transforms)\n","#del folds_paths[test_set_fold_indx]\n","#for i in range(len(folds_paths)):\n","#  folds_paths[i] = OneCoinSideDataset(folds_paths[i],False, transform=train_transforms) \n","\n","test_data = torchvision.datasets.ImageFolder(folds_paths[test_set_fold_indx], transform=test_transforms)\n","del folds_paths[test_set_fold_indx]\n","for i in range(len(folds_paths)):\n","  folds_paths[i] = torchvision.datasets.ImageFolder(folds_paths[i], transform=train_transforms)   \n","\n","train_data = torch.utils.data.ConcatDataset(folds_paths) \n","\n","#train_data = OneCoinSideDataset(train_dir,True, transform=train_transforms)                                       \n","#test_data = OneCoinSideDataset(test_dir,True, transform=test_transforms)\n","#train_data, val_data = random_split(train_data, [trainset_size, valset_size])\n","\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n","\n","give_mean_std(trainloader)\n","give_mean_std(testloader)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHkNew88Zu8q"},"source":["  for img in train_data.imgs:\n","    width, height = Image.open(img[0]).size\n","    widthh += width\n","    heighth += height\n","\n","  for img in test_data.imgs:\n","    width, height = Image.open(img[0]).size\n","    widthh += width\n","    heighth += height\n","\n","\n","  print(widthh/(len(train_data.imgs) + len(test_data.imgs)))\n","  print(heighth/(len(train_data.imgs) + len(test_data.imgs)))\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NzXwM9frrFD"},"source":["def plot_images2(loader, n_batches):\n","\n","    rows = int(np.sqrt(n_batches*batch_size))+1\n","    cols = int(np.sqrt(n_batches*batch_size))+1\n","    fig = plt.figure(figsize = (8, 8))\n","    loader_iter = iter(loader)\n","    for i in range(n_batches):\n","        images, labels = next(loader_iter)\n","        images = images.permute(0,2,3,1)\n","        for j in range(batch_size):\n","          ax = fig.add_subplot(rows, cols, i*batch_size+j+1)\n","          ax.imshow(images[j])\n","          ax.set_title(int(labels[j]))\n","          ax.axis('off')\n","    #print(loader.dataset.class_to_idx)\n","\n","plot_images2(testloader,1)\n","plot_images2(trainloader,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1AuyUGEr3zZ"},"source":["from torchvision import models\n","from efficientnet_pytorch import EfficientNet\n","model = EfficientNet.from_pretrained('efficientnet-b2', num_classes=30).to(device)\n","#resnet = EfficientNet.from_name('efficientnet-b0', num_classes=30).to(device)\n","\n","#resnet = models.resnet34(pretrained=False, num_classes = 2).to(device)\n","\n","#model = models.resnet34(pretrained=True).to(device)\n","#num_ftrs = resnet.fc.in_features\n","#resnet.fc = nn.Linear(num_ftrs, 2).to(device)\n","\n","save_path = '/content/gdrive/MyDrive/magisterka/models/FOLD4_KINGS_BOTHSIDEACCE.pt'\n","torch.cuda.empty_cache()\n","optimizer = optim.Adam(model.parameters(), lr = 0.01)\n","num_epochs = 100\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"noA35JCexB_3"},"source":["from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","import sklearn.metrics as metrics\n","\n","def save_checkpoint(save_path, model, optimizer, val_loss):\n","    if save_path==None:\n","        return\n","    save_path = save_path \n","    state_dict = {'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'val_loss': val_loss}\n","\n","    torch.save(state_dict, save_path)\n","\n","    print(f'Model saved to ==> {save_path}')\n","\n","def load_checkpoint(model, optimizer, path):\n","    save_path = path\n","    state_dict = torch.load(save_path, map_location=torch.device(device))\n","    model.load_state_dict(state_dict['model_state_dict'])\n","    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n","    val_loss = state_dict['val_loss']\n","    print(f'Model loaded from <== {save_path}')\n","    \n","    return val_loss\n","\n","\n","def train(model, train_loader, test_loader, num_epochs, criterion, save_name):\n","    best_val_loss = float(\"Inf\") \n","    train_losses = []\n","    val_losses = []\n","    cur_step = 0\n","    best_accuracy = 5\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        accuracy = eval(model, test_loader)\n","        if best_accuracy < accuracy:\n","            best_accuracy = accuracy\n","            save_checkpoint(save_name, model, optimizer, train_losses)\n","        \n","        model.train()\n","        print(\" Starting epoch \" + str(epoch+1))\n","        for img1, labels in train_loader:\n","            # Forward\n","            img1 = img1.to(device)\n","            labels = labels.to(device)\n","            outputs = model(img1)\n","            loss = criterion(outputs, labels)\n","            \n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        avg_train_loss = running_loss / len(train_loader)\n","        train_losses.append(avg_train_loss)\n","        print(\"Training loss \" + str(train_losses[-1]))\n","        \n","    print(\"Finished Training\")  \n","    return train_losses, val_losses  \n","\n","# evaluation metrics\n","def eval(model, test_loader):\n","    y_test = []\n","    y_pred = []\n","    with torch.no_grad():\n","        model.eval()\n","        correct = 0\n","        count = 0\n","        for img1, labels in test_loader:\n","            # Forward\n","            img1 = img1.to(device)\n","            outputs = model(img1).to(device)\n","            _, preds = torch.max(outputs, 1)\n","            y_pred.extend(preds.tolist())\n","            y_test.extend(labels.tolist())\n","            labels = labels.to(device)\n","            for i in range(len(labels)):\n","              if labels[i] == preds[i]:\n","                correct = correct+1\n","              count = count +1\n","\n","        accuracy = (correct/count)*100\n","    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n","    if (False):\n","      print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='macro'))    \n","      print(\"F1 score:\",metrics.f1_score(y_test, y_pred, average='macro'))\n","      cm = metrics.confusion_matrix(y_test, y_pred)\n","      print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='macro'))\n","      print(\"Confusion matrix:\",cm)\n","      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","      print(cm.diagonal())\n","      #return accuracy\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNT2_XOgyd6P"},"source":["num_epochs = 100\n","train_losses, val_losses = train(model, trainloader, testloader, num_epochs, criterion, save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HF6y47PqDxD8"},"source":["print(len(train_losses))\n","train_losses2 = train_losses\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hsjasdNyFeg"},"source":["train_losses = train_losses2 + train_losses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8MDuErxVzNfl"},"source":["save_path ='/content/gdrive/MyDrive/magisterka/models/' + 'FOLD5_KINGS_BOTHSIDEACC85.16E82.pt'\n","#t_loader = trainloader\n","t_loader = testloader\n","train_losses = load_checkpoint(model, optimizer, save_path)\n","#accuracy = eval (model,t_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4oinPUPu1DL"},"source":["img = next(iter(testloader))\n","print(img[1])\n","img = img[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtHKhqd5s5p2"},"source":["named_layers = dict(model.named_modules())\n","for moudle in model.named_modules():\n","  print(moudle)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xawGYWTfA-Hq"},"source":["print(named_layers['_blocks.22._project_conv'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbSFz_p0klRg"},"source":["!pip install ttach\n","!pip install grad-cam\n","\n","\n","from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n","from pytorch_grad_cam.utils.image import show_cam_on_image\n","from torchvision.models import resnet50\n","import argparse\n","\n","torch.cuda.empty_cache()\n","target_layer = named_layers['_conv_head']\n","input_tensor = img# Create an input tensor image for your model..\n","# Note: input_tensor can be a batch tensor with several images!\n","\n","# Construct the CAM object once, and then re-use it on many images:\n","cam = GradCAM(model=model, target_layer=target_layer, use_cuda=False)\n","\n","# If target_category is None, the highest scoring category\n","# will be used for every image in the batch.\n","# target_category can also be an integer, or a list of different integers\n","# for every image in the batch.\n","target_category = 29\n","\n","# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n","grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDbXgYFUp1oF"},"source":["index = 22\n","\n","MEAN = torch.tensor([0.485, 0.456, 0.406])\n","STD = torch.tensor([0.229, 0.224, 0.225])\n","\n","x = img[index] * STD[:, None, None] + MEAN[:, None, None]\n","\n","grayscale_c = grayscale_cam[index, :]\n","rgb_img = np.float32(x.permute(1,2,0))\n","visualization = show_cam_on_image(rgb_img, grayscale_c, use_rgb = True)\n","#plt.imshow(visualization, cmap='gray')\n","plt.figure()\n","\n","f, axarr = plt.subplots(1,2) ;\n","\n","\n","\n","# use the created array to output your multiple images. In this case I have stacked 4 images vertically\n","axarr[0].imshow(visualization)\n","axarr[1].imshow(x.permute(1,2,0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J00vOwdD6IL9"},"source":["print(train_losses)\n","#plotting of training and validation loss\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.plot(train_losses, label='Train Loss')\n","plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]}]}